{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d512ff36-4561-406a-88ff-ad32c2fbc897",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a1459-e7fc-4dab-a5a1-f65d5cdb3202",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f61be-87b4-4746-a04c-8f0d3b911e67",
   "metadata": {},
   "source": [
    "Uncomment the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf16760-0e24-49cb-9250-d14786cfe552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ricgama/maenvs4vrp_beta.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce8b10-fad6-4a2d-8c11-a61e3e606b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using Colab\n",
    "# %cd maenvs4vrp_beta/\n",
    "# ! pip install -e .\n",
    "#%cd maenvs4vrp/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cd1bd",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e419715",
   "metadata": {},
   "source": [
    "Let's explore the library using the CVRPTW environment as an example. Our API structure is inspired by [PettingZoo](https://pettingzoo.farama.org/), following the Agent Environment Cycle (AEC) philosophy. We have been also greatly influenced by [Flatland's](https://flatland.aicrowd.com/intro.html) environment library, and we chose to adopt some of its design principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maenvs4vrp.environments.cvrptw.env import Environment\n",
    "from maenvs4vrp.environments.cvrptw.env_agent_selector import AgentSelector\n",
    "from maenvs4vrp.environments.cvrptw.observations import Observations\n",
    "from maenvs4vrp.environments.cvrptw.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.cvrptw.env_agent_reward import DenseReward\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size = 8)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size = 8, num_agents=4, num_nodes=16)\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f3386",
   "metadata": {},
   "source": [
    "## Quick walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4d0ba",
   "metadata": {},
   "source": [
    "Let's now go through the library's building blocks, exploring their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc26a8",
   "metadata": {},
   "source": [
    "### Instance generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451a64f",
   "metadata": {},
   "source": [
    "We can generate instances using one of the two available methods `InstanceGenerator` and `BenchmarkInstanceGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maenvs4vrp.environments.cvrptw.instances_generator import InstanceGenerator\n",
    "from maenvs4vrp.environments.cvrptw.benchmark_instances_generator import BenchmarkInstanceGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2261c",
   "metadata": {},
   "source": [
    "#### Random generated instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623a211",
   "metadata": {},
   "source": [
    "Random instances are generated following:\n",
    "\n",
    "Li, S., Yan, Z., & Wu, C. (2021). [Learning to delegate for large-scale vehicle routing](https://proceedings.neurips.cc/paper/2021/hash/dc9fa5f217a1e57b8a6adeb065560b38-Abstract.html). Advances in Neural Information Processing Systems, 34, 26198-26211."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InstanceGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance(num_agents=2, num_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b10f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32f1ee",
   "metadata": {},
   "source": [
    "It's possible to load a set of pre-generaded instances, to be used as validation/test sets. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e681fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_instances = set(generator.get_list_of_benchmark_instances()['servs_100_agents_25']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InstanceGenerator(instance_type='validation', set_of_instances=set_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badb78b",
   "metadata": {},
   "source": [
    "Let's check instance dict keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b966652",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab722ca0",
   "metadata": {},
   "source": [
    "#### Benchmark instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de3909",
   "metadata": {},
   "source": [
    "In order to narrow the current gap between the test beds for algorithm benchmarking used in RL\n",
    "and OR communities, the library allows a straightforward integration of classical OR benchmark\n",
    "instances. For example, we can load a set of classical benchmark instances. Let's see what benchmark instances we have for the CVPTW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchmarkInstanceGenerator.get_list_of_benchmark_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408dbea3",
   "metadata": {},
   "source": [
    "Ok! Now we instanciate the `generator` selecting two of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = BenchmarkInstanceGenerator(instance_type='Solomon', set_of_instances={'C101', 'C102'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101 = generator.get_instance('C101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ae8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101['num_agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf290c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c101['num_nodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44070687",
   "metadata": {},
   "source": [
    "By customizing `.sample_instance` method arguments, it is possible to sample a sub-instance of the original instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e34566",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance(num_agents=3, num_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe50e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c05616",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance['num_agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance['num_nodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821778f",
   "metadata": {},
   "source": [
    "For the CVRPTW, setting `random_sample=False` we sample first `n` instace services (see  [Transportation Optimization Portal](https://www.sintef.no/projectweb/top/vrptw) for more details about `first n` Solomon benchmark\n",
    " instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = generator.sample_instance(num_agents=3, num_nodes=8, sample_type='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c39b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2a1dd",
   "metadata": {},
   "source": [
    "###  Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f56b8",
   "metadata": {},
   "source": [
    "Observation features, that will be available to the active agent while interacting with the environment, are handle by `Observations` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maenvs4vrp.environments.cvrptw.observations import Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = Observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e4b04",
   "metadata": {},
   "source": [
    "The class has a `default_feature_list` attribute where the default configuration dictionary is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.default_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cec072",
   "metadata": {},
   "source": [
    "Also, five possible features lists exist, detailing the available features in the class: `POSSIBLE_NODES_STATIC_FEATURES`, `POSSIBLE_NODES_DYNAMIC_FEATURES`, `POSSIBLE_SELF_FEATURES`, `POSSIBLE_AGENTS_FEATURES`, `POSSIBLE_GLOBAL_FEATURES`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.POSSIBLE_NODES_STATIC_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.POSSIBLE_GLOBAL_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61f210",
   "metadata": {},
   "source": [
    "While instantiating the `Observations` class, we can pass through a feature list dictionary specifying which features will be available for the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = yaml.safe_load(\"\"\"\n",
    "    nodes_static:\n",
    "        x_coordinate_min_max:\n",
    "            feat: x_coordinate_min_max\n",
    "            norm: min_max\n",
    "        x_coordinate_min_max: \n",
    "            feat: x_coordinate_min_max\n",
    "            norm: min_max\n",
    "        tw_low_mm:\n",
    "            feat: tw_low\n",
    "            norm: min_max\n",
    "        tw_high:\n",
    "            feat: tw_high\n",
    "            norm: min_max\n",
    "\n",
    "    nodes_dynamic:\n",
    "        - time2open_div_end_time\n",
    "        - time2close_div_end_time\n",
    "        - time2open_after_step_div_end_time\n",
    "        - time2close_after_step_div_end_time\n",
    "        - fract_time_after_step_div_end_time\n",
    "\n",
    "    agent:\n",
    "        - x_coordinate_min_max\n",
    "        - y_coordinate_min_max\n",
    "        - frac_current_time\n",
    "        - frac_current_load\n",
    "\n",
    "    other_agents:\n",
    "        - x_coordinate_min_max\n",
    "        - y_coordinate_min_max\n",
    "        - frac_current_time\n",
    "        - frac_current_load\n",
    "        - dist2agent_div_end_time\n",
    "    \n",
    "    global:\n",
    "        - frac_demands\n",
    "        - frac_fleet_load_capacity\n",
    "        - frac_done_agents\n",
    "        - frac_not_done_nodes\n",
    "        - frac_used_agents\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = Observations(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7bbd6",
   "metadata": {},
   "source": [
    "We can test these observations on the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841178da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size=8)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09332ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.reset(batch_size = 8, num_agents=4, num_nodes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_observation = env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704aa1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b83ef",
   "metadata": {},
   "source": [
    "###  Agent Selector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maenvs4vrp.environments.cvrptw.env_agent_selector import AgentSelector, SmallestTimeAgentSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8728d5f",
   "metadata": {},
   "source": [
    "With `AgentSelector` class, the same agent is selected until it returns to the depot. Afterward, it selects the next active agent and repeats the process until all agents are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32319404",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size = 1)\n",
    "obs = Observations()\n",
    "sel = AgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)\n",
    "\n",
    "td = env.reset()\n",
    "\n",
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)\n",
    "    step = env.env_nsteps\n",
    "    cur_agent_idx = td['cur_agent_idx']\n",
    "    print(f'env step number: {step}, active agent name: {cur_agent_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef431706",
   "metadata": {},
   "source": [
    "With `SmallesttimeAgentSelector` class, The agent with the shortest travel time is selected, until all agents have finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = InstanceGenerator(batch_size = 1)\n",
    "obs = Observations()\n",
    "sel = SmallestTimeAgentSelector()\n",
    "rew = DenseReward()\n",
    "\n",
    "env = Environment(instance_generator_object=gen,  \n",
    "                  obs_builder_object=obs,\n",
    "                  agent_selector_object=sel,\n",
    "                  reward_evaluator=rew,\n",
    "                  seed=0)\n",
    "\n",
    "td = env.reset()\n",
    "\n",
    "while not td[\"done\"].all():  \n",
    "    td = env.sample_action(td) # this is where we insert our policy\n",
    "    td = env.step(td)\n",
    "    step = env.env_nsteps\n",
    "    cur_agent_idx = td['cur_agent_idx']\n",
    "    print(f'env step number: {step}, active agent name: {cur_agent_idx}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4vrp_env",
   "language": "python",
   "name": "rl4vrp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
